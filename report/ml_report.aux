\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{plainnat}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Reinforcement Learning}{1}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Problem Formulation}{1}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Algorithms and Approaches}{2}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Value-based methods}{2}{subsubsection.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Policy-based methods}{2}{subsubsection.2.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Policy Gradient}{3}{subsubsection.2.2.3}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces \textbf  {REINFORCE}}}{5}{figure.caption.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces REINFORCE pseudo code algorithm.}}{5}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:reinforce}{{1}{5}{REINFORCE pseudo code algorithm}{figure.caption.1}{}}
\newlabel{fig:reinforce@cref}{{[figure][1][]1}{[1][4][]5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4}Proximal Policy Optimization}{5}{subsubsection.2.2.4}\protected@file@percent }
\citation{schulman2017proximal}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces \textbf  {Proximal Policy Optimization}}}{6}{figure.caption.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces PPO pseudo code algorithm.}}{6}{figure.caption.2}\protected@file@percent }
\newlabel{fig:ppo}{{2}{6}{PPO pseudo code algorithm}{figure.caption.2}{}}
\newlabel{fig:ppo@cref}{{[figure][2][]2}{[1][6][]6}}
\citation{schulman2017proximal}
\@writefile{toc}{\contentsline {section}{\numberline {3}Experiment Setup}{7}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Experiment Objective}{7}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}LunarLander Environment}{7}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Rewards}{7}{subsection.3.3}\protected@file@percent }
\citation{Nvid.CUDA}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Implementation}{8}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}PPO}{8}{subsubsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}REINFORCE}{8}{subsubsection.3.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.3}Reproducibility}{8}{subsubsection.3.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiment Results}{9}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}PPO}{9}{subsection.4.1}\protected@file@percent }
\newlabel{fig:ppo_rewcust}{{3a}{9}{Project-custom rewards}{figure.caption.3}{}}
\newlabel{fig:ppo_rewcust@cref}{{[subfigure][1][3]3a}{[1][8][]9}}
\newlabel{sub@fig:ppo_rewcust}{{a}{9}{Project-custom rewards}{figure.caption.3}{}}
\newlabel{sub@fig:ppo_rewcust@cref}{{[subfigure][1][3]3a}{[1][8][]9}}
\newlabel{fig:ppo_rewdef}{{3b}{9}{Default rewards}{figure.caption.3}{}}
\newlabel{fig:ppo_rewdef@cref}{{[subfigure][2][3]3b}{[1][8][]9}}
\newlabel{sub@fig:ppo_rewdef}{{b}{9}{Default rewards}{figure.caption.3}{}}
\newlabel{sub@fig:ppo_rewdef@cref}{{[subfigure][2][3]3b}{[1][8][]9}}
\newlabel{fig:ppo_rewcomb}{{3c}{9}{Combined rewards}{figure.caption.3}{}}
\newlabel{fig:ppo_rewcomb@cref}{{[subfigure][3][3]3c}{[1][8][]9}}
\newlabel{sub@fig:ppo_rewcomb}{{c}{9}{Combined rewards}{figure.caption.3}{}}
\newlabel{sub@fig:ppo_rewcomb@cref}{{[subfigure][3][3]3c}{[1][8][]9}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Training and evaluation rewards of PPO for different reward configurations, namely the custom reward configuration proposed in the course project description, the default reward configuration of the environment, and a combination of both.}}{9}{figure.caption.3}\protected@file@percent }
\newlabel{fig:ppo_reward}{{3}{9}{Training and evaluation rewards of PPO for different reward configurations, namely the custom reward configuration proposed in the course project description, the default reward configuration of the environment, and a combination of both}{figure.caption.3}{}}
\newlabel{fig:ppo_reward@cref}{{[figure][3][]3}{[1][8][]9}}
\newlabel{fig:ppo_lr0.01}{{4a}{10}{$\alpha =0.01$}{figure.caption.4}{}}
\newlabel{fig:ppo_lr0.01@cref}{{[subfigure][1][4]4a}{[1][9][]10}}
\newlabel{sub@fig:ppo_lr0.01}{{a}{10}{$\alpha =0.01$}{figure.caption.4}{}}
\newlabel{sub@fig:ppo_lr0.01@cref}{{[subfigure][1][4]4a}{[1][9][]10}}
\newlabel{fig:ppo_lr0.001}{{4b}{10}{$\alpha =0.001$}{figure.caption.4}{}}
\newlabel{fig:ppo_lr0.001@cref}{{[subfigure][2][4]4b}{[1][9][]10}}
\newlabel{sub@fig:ppo_lr0.001}{{b}{10}{$\alpha =0.001$}{figure.caption.4}{}}
\newlabel{sub@fig:ppo_lr0.001@cref}{{[subfigure][2][4]4b}{[1][9][]10}}
\newlabel{fig:ppo_lr0.0003}{{4c}{10}{$\alpha =0.0003$}{figure.caption.4}{}}
\newlabel{fig:ppo_lr0.0003@cref}{{[subfigure][3][4]4c}{[1][9][]10}}
\newlabel{sub@fig:ppo_lr0.0003}{{c}{10}{$\alpha =0.0003$}{figure.caption.4}{}}
\newlabel{sub@fig:ppo_lr0.0003@cref}{{[subfigure][3][4]4c}{[1][9][]10}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Training and evaluation rewards of PPO for different learning rates $\alpha =0.01,0.001,0.0003$.}}{10}{figure.caption.4}\protected@file@percent }
\newlabel{fig:ppo_lr}{{4}{10}{Training and evaluation rewards of PPO for different learning rates $\alpha =0.01,0.001,0.0003$}{figure.caption.4}{}}
\newlabel{fig:ppo_lr@cref}{{[figure][4][]4}{[1][9][]10}}
\newlabel{fig:ppo_gamma0.5}{{5a}{11}{$\gamma =0.5$}{figure.caption.5}{}}
\newlabel{fig:ppo_gamma0.5@cref}{{[subfigure][1][5]5a}{[1][10][]11}}
\newlabel{sub@fig:ppo_gamma0.5}{{a}{11}{$\gamma =0.5$}{figure.caption.5}{}}
\newlabel{sub@fig:ppo_gamma0.5@cref}{{[subfigure][1][5]5a}{[1][10][]11}}
\newlabel{fig:ppo_gamma0.7}{{5b}{11}{$\gamma =0.7$}{figure.caption.5}{}}
\newlabel{fig:ppo_gamma0.7@cref}{{[subfigure][2][5]5b}{[1][10][]11}}
\newlabel{sub@fig:ppo_gamma0.7}{{b}{11}{$\gamma =0.7$}{figure.caption.5}{}}
\newlabel{sub@fig:ppo_gamma0.7@cref}{{[subfigure][2][5]5b}{[1][10][]11}}
\newlabel{fig:ppo_gamma0.999}{{5c}{11}{$\gamma =0.999$}{figure.caption.5}{}}
\newlabel{fig:ppo_gamma0.999@cref}{{[subfigure][3][5]5c}{[1][10][]11}}
\newlabel{sub@fig:ppo_gamma0.999}{{c}{11}{$\gamma =0.999$}{figure.caption.5}{}}
\newlabel{sub@fig:ppo_gamma0.999@cref}{{[subfigure][3][5]5c}{[1][10][]11}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Training and evaluation rewards of PPO for different discount rates $\gamma =0.5,0.7,0.999$.}}{11}{figure.caption.5}\protected@file@percent }
\newlabel{fig:ppo_gamma}{{5}{11}{Training and evaluation rewards of PPO for different discount rates $\gamma =0.5,0.7,0.999$}{figure.caption.5}{}}
\newlabel{fig:ppo_gamma@cref}{{[figure][5][]5}{[1][10][]11}}
\bibdata{references.bib}
\bibcite{Nvid.CUDA}{{1}{2023}{{affiliates}}{{}}}
\bibcite{schulman2017proximal}{{2}{2017}{{Schulman et~al.}}{{Schulman, Wolski, Dhariwal, Radford, and Klimov}}}
\newlabel{fig:ppo_cr01}{{6a}{12}{$\varepsilon =0.1$}{figure.caption.6}{}}
\newlabel{fig:ppo_cr01@cref}{{[subfigure][1][6]6a}{[1][11][]12}}
\newlabel{sub@fig:ppo_cr01}{{a}{12}{$\varepsilon =0.1$}{figure.caption.6}{}}
\newlabel{sub@fig:ppo_cr01@cref}{{[subfigure][1][6]6a}{[1][11][]12}}
\newlabel{fig:ppo_cr03}{{6b}{12}{$\varepsilon =0.3$}{figure.caption.6}{}}
\newlabel{fig:ppo_cr03@cref}{{[subfigure][2][6]6b}{[1][11][]12}}
\newlabel{sub@fig:ppo_cr03}{{b}{12}{$\varepsilon =0.3$}{figure.caption.6}{}}
\newlabel{sub@fig:ppo_cr03@cref}{{[subfigure][2][6]6b}{[1][11][]12}}
\newlabel{fig:ppo_cr02}{{6c}{12}{$\varepsilon =0.2$}{figure.caption.6}{}}
\newlabel{fig:ppo_cr02@cref}{{[subfigure][3][6]6c}{[1][11][]12}}
\newlabel{sub@fig:ppo_cr02}{{c}{12}{$\varepsilon =0.2$}{figure.caption.6}{}}
\newlabel{sub@fig:ppo_cr02@cref}{{[subfigure][3][6]6c}{[1][11][]12}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Training and evaluation rewards of PPO for different clip rates $\varepsilon =0.1,0.2,0.3$}}{12}{figure.caption.6}\protected@file@percent }
\newlabel{fig:ppo_cliprate}{{6}{12}{Training and evaluation rewards of PPO for different clip rates $\varepsilon =0.1,0.2,0.3$}{figure.caption.6}{}}
\newlabel{fig:ppo_cliprate@cref}{{[figure][6][]6}{[1][11][]12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}REINFORCE}{12}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{12}{section.5}\protected@file@percent }
\gdef \@abspage@last{12}
